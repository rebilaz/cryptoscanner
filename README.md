# CryptoScanner

CryptoScanner is a modular crypto market analysis pipeline built around Google BigQuery. The project collects market data from centralized exchanges and onâ€‘chain sources, computes strategy indicators, produces trading decisions and sends Telegram alerts.

## Repository structure

```
cryptoscanner/
â”œâ”€â”€ cryptoscanner/
â”‚   â”œâ”€â”€ bigquery_client.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ module_1_1.py  # CEX ingestion
â”‚   â”œâ”€â”€ module_1_2.py  # CEX indicators
â”‚   â”œâ”€â”€ module_1_3.py  # Decision engine
â”‚   â”œâ”€â”€ module_2_1.py  # Dune ingestion
â”‚   â”œâ”€â”€ module_2_1_1.py  # Public BigQuery ingestion
â”‚   â”œâ”€â”€ module_2_2.py  # Onâ€‘chain indicators
â”‚   â”œâ”€â”€ module_2_3.py  # Anomaly detection
â”‚   â””â”€â”€ module_3_1.py  # Telegram alerting
â”œâ”€â”€ tests/
â”œâ”€â”€ run_pipeline.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

## Installation

1. Clone the repository and create a virtual environment:

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

2. Copy `.env.example` to `.env` and fill in the variables:

- `DUNE_API_KEY` â€“ API key for Dune Analytics
- `TELEGRAM_TOKEN` and `TELEGRAM_CHAT_ID` â€“ Telegram bot credentials
- `LOG_LEVEL` â€“ logging level (INFO by default)

3. Ensure the IAM identity running the code has `BigQuery Data Editor` on the
   dataset `cryptoscanner` and `BigQuery Job User` on the project
   `starlit-verve-458814-u9`.

## BigQuery authentication

The pipeline relies on [Application Default Credentials](https://cloud.google.com/docs/authentication/production#automatically) (ADC).
No service account JSON file is required. When running on AWS or other
infrastructure, configure Workload Identity Federation or an instance profile so
that `google-cloud-bigquery` can obtain credentials automatically. Any
`GOOGLE_APPLICATION_CREDENTIALS` environment variable will be ignored.

## Running the pipeline

The example script `run_pipeline.py` executes the full workflow:

```bash
python run_pipeline.py
```

A typical Telegram alert message looks like:

```
ðŸš€ *BTC* decision: LONG
```

## Tests

Run all unit tests with `pytest`:

```bash
pytest
```

## Cloud deployment notes

The modules are selfâ€‘contained functions and can be orchestrated with cron jobs or container schedulers (Docker/Kubernetes). For secret management, use GCP Secret Manager or AWS Secrets Manager and export the values to the environment before running the pipeline.

# 1. Active ton environnement virtuel (si pas dÃ©jÃ  fait)
source .venv/bin/activate

# 2. Lance le pipeline principal
python run_pipeline.py